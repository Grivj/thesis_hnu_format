\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\bibstyle{hnunumerical}
\HyPL@Entry{0<</P()>>}
\providecommand \oddpage@label [2]{}
\pgfsyspdfmark {pgfid1}{7545713}{47508770}
\pgfsyspdfmark {pgfid2}{7545713}{45798460}
\pgfsyspdfmark {pgfid3}{7803048}{45798460}
\pgfsyspdfmark {pgfid4}{8060383}{45798460}
\pgfsyspdfmark {pgfid5}{7545713}{44088150}
\pgfsyspdfmark {pgfid6}{7545713}{47508770}
\pgfsyspdfmark {pgfid7}{7545713}{45798460}
\pgfsyspdfmark {pgfid8}{7545713}{44088150}
\pgfsyspdfmark {pgfid9}{7545713}{42377840}
\HyPL@Entry{2<</P()>>}
\pgfsyspdfmark {pgfid10}{7545713}{47508770}
\pgfsyspdfmark {pgfid11}{7803048}{47508770}
\pgfsyspdfmark {pgfid12}{8060383}{47508770}
\pgfsyspdfmark {pgfid13}{8317718}{47508770}
\pgfsyspdfmark {pgfid14}{7545713}{45798460}
\pgfsyspdfmark {pgfid15}{7803048}{45798460}
\pgfsyspdfmark {pgfid16}{8060383}{45798460}
\pgfsyspdfmark {pgfid17}{8317718}{45798460}
\pgfsyspdfmark {pgfid18}{8575053}{45798460}
\pgfsyspdfmark {pgfid19}{8832388}{45798460}
\pgfsyspdfmark {pgfid20}{9089723}{45798460}
\pgfsyspdfmark {pgfid21}{9347058}{45798460}
\pgfsyspdfmark {pgfid22}{9604393}{45798460}
\pgfsyspdfmark {pgfid23}{9861728}{45798460}
\pgfsyspdfmark {pgfid24}{10119063}{45798460}
\pgfsyspdfmark {pgfid25}{10376398}{45798460}
\HyPL@Entry{3<</S/R>>}
\@writefile{toc}{\contentsline {chapter}{学位论文原创性声明和学位论文版权使用授权书}{I}{Doc-Start}\protected@file@percent }
\HyPL@Entry{5<</S/R /St 2>>}
\HyPL@Entry{6<</S/R /St 2>>}
\@writefile{toc}{\contentsline {chapter}{摘\hskip 1em\relax 要}{II}{chapter*.1}\protected@file@percent }
\HyPL@Entry{8<</S/R /St 3>>}
\@writefile{toc}{\contentsline {chapter}{Abstract}{IV}{chapter*.2}\protected@file@percent }
\HyPL@Entry{10<</S/R /St 4>>}
\@writefile{toc}{\contentsline {chapter}{插图索引}{VII}{chapter*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{附表索引}{X}{chapter*.5}\protected@file@percent }
\citation{russakovsky_imagenet_2015,amodei_deep_2015}
\citation{bojarski_end_2016}
\citation{silver_mastering_2016}
\citation{szegedy_intriguing_2014}
\citation{carlini_audio_2018}
\citation{carlini_audio_2018}
\citation{carlini_audio_2018}
\citation{su_one_2019}
\HyPL@Entry{17<</S/D>>}
\@writefile{toc}{\contentsline {chapter}{\numberline {第1章\hspace  {.3em}}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10.0pt}}
\@writefile{lot}{\addvspace {10.0pt}}
\newlabel{Introduction}{{1}{1}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Motivation}{1}{section.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Normal image (A), adversarial perturbation (B), adversarial example (C). The model accurately classifies the normal image as a "white shark" while misclassifying the adversarial example as a "prairie chicken."\relax }}{1}{figure.caption.6}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:adversarial_examples}{{1.1}{1}{Normal image (A), adversarial perturbation (B), adversarial example (C). The model accurately classifies the normal image as a "white shark" while misclassifying the adversarial example as a "prairie chicken."\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\centering }}}{1}{subfigure.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\centering }}}{1}{subfigure.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {\centering }}}{1}{subfigure.1.3}\protected@file@percent }
\citation{su_one_2019}
\citation{su_one_2019}
\citation{he_deep_2015,vaswani_attention_2017,huang_densely_2018}
\citation{srivastava_dropout_2014}
\citation{hendrycks_benchmarking_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces  Unnoticeable audio waveform added to an audio recording changes the transcription by the model drastically \cite  {carlini_audio_2018}.\relax }}{2}{figure.caption.7}\protected@file@percent }
\newlabel{fig:carlini_audio}{{1.2}{2}{Unnoticeable audio waveform added to an audio recording changes the transcription by the model drastically \cite {carlini_audio_2018}.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces  One-pixel attack \cite  {su_one_2019}. Modified pixels are circled in red. Original predictions in black and predictions with modified pixels in blue.\relax }}{2}{figure.caption.8}\protected@file@percent }
\newlabel{fig:su_one_pixel}{{1.3}{2}{One-pixel attack \cite {su_one_2019}. Modified pixels are circled in red. Original predictions in black and predictions with modified pixels in blue.\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces  Normal image (A), noisy image (B), adversarial example (C). The model accurately predicts both the normal image and noisy image but misclassifies the adversarial example, despite the adversarial perturbation being $\approx {20}$ times smaller than the random perturbation in that case. \relax }}{3}{figure.caption.9}\protected@file@percent }
\newlabel{fig:noise}{{1.4}{3}{Normal image (A), noisy image (B), adversarial example (C). The model accurately predicts both the normal image and noisy image but misclassifies the adversarial example, despite the adversarial perturbation being $\approx {20}$ times smaller than the random perturbation in that case. \relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{3}{subfigure.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{3}{subfigure.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{3}{subfigure.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Main Contribution}{4}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Thesis Structure}{4}{section.1.3}\protected@file@percent }
\citation{warren_s_mcculloch_walter_pitts_logical_1943}
\citation{brain_perceptron_1958}
\@writefile{toc}{\contentsline {chapter}{\numberline {第2章\hspace  {.3em}}Related Work}{5}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10.0pt}}
\@writefile{lot}{\addvspace {10.0pt}}
\newlabel{RelatedWork}{{2}{5}{Related Work}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}A Brief History of Neural Networks}{5}{section.2.1}\protected@file@percent }
\newlabel{history_of_neural_networks}{{2.1}{5}{A Brief History of Neural Networks}{section.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces  Representation of a biological neuron. \relax }}{5}{figure.caption.10}\protected@file@percent }
\newlabel{fig:biological_neuron}{{2.1}{5}{Representation of a biological neuron. \relax }{figure.caption.10}{}}
\citation{minsky_perceptrons_1969}
\citation{haykin_neural_1994}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces  McCulloch-Pitts Neuron, first mathematical model of a neuron. \relax }}{6}{figure.caption.11}\protected@file@percent }
\newlabel{fig:mccullock_neuron}{{2.2}{6}{McCulloch-Pitts Neuron, first mathematical model of a neuron. \relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {(1)}Neural networks,}{6}{paragraph.2.1.0.0.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces  Representation of an artificial Neuron. \relax }}{7}{figure.caption.12}\protected@file@percent }
\newlabel{fig:artificial_neuron}{{2.3}{7}{Representation of an artificial Neuron. \relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces  Fully connected neural network containing two hidden layers. \relax }}{8}{figure.caption.13}\protected@file@percent }
\newlabel{fig:fcnn}{{2.4}{8}{Fully connected neural network containing two hidden layers. \relax }{figure.caption.13}{}}
\newlabel{eq:fcnn_layer_1}{{2.1}{8}{Neural networks,}{equation.2.1.1}{}}
\newlabel{eq:fcnn_layer_1_vec}{{2.2}{8}{Neural networks,}{equation.2.1.2}{}}
\newlabel{eq:fcnn_layer_2_vec}{{2.3}{9}{Neural networks,}{equation.2.1.3}{}}
\newlabel{eq:fcnn_layer_last}{{2.4}{9}{Neural networks,}{equation.2.1.4}{}}
\newlabel{eq:fcnn_layer_last_vec}{{2.5}{9}{Neural networks,}{equation.2.1.5}{}}
\newlabel{eq:softmax}{{2.6}{9}{Neural networks,}{equation.2.1.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces  Widely used activation functions. \relax }}{10}{figure.caption.14}\protected@file@percent }
\newlabel{fig:activation_functions}{{2.5}{10}{Widely used activation functions. \relax }{figure.caption.14}{}}
\newlabel{eq:relu}{{2.7}{10}{Neural networks,}{equation.2.1.7}{}}
\citation{rumelhart_learning_1986}
\newlabel{eq:leaky_relu}{{2.8}{11}{Neural networks,}{equation.2.1.8}{}}
\newlabel{eq:cross-entropy}{{2.9}{11}{Neural networks,}{equation.2.1.9}{}}
\citation{lecun_object_1999}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Convolutional Neural Networks: A Closer Look}{12}{section.2.2}\protected@file@percent }
\newlabel{CNNs}{{2.2}{12}{Convolutional Neural Networks: A Closer Look}{section.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces  Architecture of a classic convolutional neural network. \relax }}{12}{figure.caption.15}\protected@file@percent }
\newlabel{fig:cnn}{{2.6}{12}{Architecture of a classic convolutional neural network. \relax }{figure.caption.15}{}}
\citation{krizhevsky_imagenet_2017-1}
\citation{krizhevsky_imagenet_2017-1}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces  $11 \times 11 \times 3$ filters learned by the first convolutional layer on $224 \times 224 \times 3$ input images, experiment by \cite  {krizhevsky_imagenet_2017-1}. \relax }}{13}{figure.caption.16}\protected@file@percent }
\newlabel{fig:kernels}{{2.7}{13}{$11 \times 11 \times 3$ filters learned by the first convolutional layer on $224 \times 224 \times 3$ input images, experiment by \cite {krizhevsky_imagenet_2017-1}. \relax }{figure.caption.16}{}}
\citation{zeiler_visualizing_2013}
\citation{zeiler_visualizing_2013}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces  Filters learned by the fifth convolutional layer, experiment by \cite  {zeiler_visualizing_2013}. \relax }}{14}{figure.caption.17}\protected@file@percent }
\newlabel{fig:kernels_5}{{2.8}{14}{Filters learned by the fifth convolutional layer, experiment by \cite {zeiler_visualizing_2013}. \relax }{figure.caption.17}{}}
\citation{noauthor_model_2020}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Adversarial Examples: A Threat to Neural Networks}{15}{section.2.3}\protected@file@percent }
\newlabel{Adversarial_examples}{{2.3}{15}{Adversarial Examples: A Threat to Neural Networks}{section.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Speed limit signs modified (B, C) that fools the Tesla model X and S (model 2016). (B) is identified as a 45-mph sign, while (C) is identified as a 85-mph speed sign.\relax }}{15}{figure.caption.18}\protected@file@percent }
\newlabel{fig:mcafee_tesla}{{2.9}{15}{Speed limit signs modified (B, C) that fools the Tesla model X and S (model 2016). (B) is identified as a 45-mph sign, while (C) is identified as a 85-mph speed sign.\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{15}{subfigure.9.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{15}{subfigure.9.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{15}{subfigure.9.3}\protected@file@percent }
\citation{goodfellow_explaining_2015}
\citation{szegedy_going_2014}
\newlabel{eq:adversarial_example_min}{{2.10}{16}{Adversarial Examples: A Threat to Neural Networks}{equation.2.3.10}{}}
\newlabel{eq:p-norm}{{2.11}{16}{Adversarial Examples: A Threat to Neural Networks}{equation.2.3.11}{}}
\citation{kurakin_adversarial_2017}
\citation{carlini_towards_2017}
\citation{papernot_distillation_2016}
\@writefile{toc}{\contentsline {paragraph}{\numberline {(1)}Fast Gradient Sign Method (FGSM).}{17}{paragraph.2.3.0.0.1}\protected@file@percent }
\newlabel{eq:fgsm}{{2.12}{17}{Fast Gradient Sign Method (FGSM)}{equation.2.3.12}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {(2)}Basic Iterative Method (BIM).}{17}{paragraph.2.3.0.0.2}\protected@file@percent }
\newlabel{eq:bim}{{2.13}{17}{Basic Iterative Method (BIM)}{equation.2.3.13}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {(3)}Carlini \& Wagner (CW).}{17}{paragraph.2.3.0.0.3}\protected@file@percent }
\newlabel{eq:cw_min}{{2.14}{17}{Carlini \& Wagner (CW)}{equation.2.3.14}{}}
\citation{rony_decoupling_2019}
\newlabel{eq:cw_lf}{{2.15}{18}{Carlini \& Wagner (CW)}{equation.2.3.15}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {(4)}Decoupled Direction and Norm (DDN).}{18}{paragraph.2.3.0.0.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces  Adversarial examples generated with different methods. The original input image (A) is correctly classified as a "church", while all the generated samples: (B), (D) and (F) are identified as a "chicken" by the model. \relax }}{19}{figure.caption.19}\protected@file@percent }
\newlabel{fig:samples_ae}{{2.10}{19}{Adversarial examples generated with different methods. The original input image (A) is correctly classified as a "church", while all the generated samples: (B), (D) and (F) are identified as a "chicken" by the model. \relax }{figure.caption.19}{}}
\citation{szegedy_intriguing_2014}
\citation{goodfellow_explaining_2015}
\citation{goodfellow_explaining_2015,papernot_limitations_2015}
\citation{papernot_distillation_2016}
\citation{carlini_adversarial_2017}
\citation{feinman_detecting_2017}
\citation{srivastava_dropout_2014}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Defending Against Adversarial Examples: Challenges and Approaches}{20}{section.2.4}\protected@file@percent }
\newlabel{sec:defending_adgainst_adversarial_examples}{{2.4}{20}{Defending Against Adversarial Examples: Challenges and Approaches}{section.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Evaluating Detection Performance: Metrics and Measures}{21}{section.2.5}\protected@file@percent }
\newlabel{eq:recall}{{2.16}{21}{Evaluating Detection Performance: Metrics and Measures}{equation.2.5.16}{}}
\newlabel{eq:precision}{{2.17}{21}{Evaluating Detection Performance: Metrics and Measures}{equation.2.5.17}{}}
\newlabel{eq:fb}{{2.18}{21}{Evaluating Detection Performance: Metrics and Measures}{equation.2.5.18}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {第3章\hspace  {.3em}}Experiments}{22}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10.0pt}}
\@writefile{lot}{\addvspace {10.0pt}}
\newlabel{Experiments}{{3}{22}{Experiments}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Intuition behind Gaussian Noise in Adversarial Examples}{22}{section.3.1}\protected@file@percent }
\newlabel{sec:experiments_overview}{{3.1}{22}{Intuition behind Gaussian Noise in Adversarial Examples}{section.3.1}{}}
\newlabel{eq:noisy_version}{{3.1}{22}{Intuition behind Gaussian Noise in Adversarial Examples}{equation.3.1.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Details for Figure \ref  {fig:noise_increase}\relax }}{22}{table.caption.21}\protected@file@percent }
\newlabel{table:noise_increase}{{3.1}{22}{Details for Figure \ref {fig:noise_increase}\relax }{table.caption.21}{}}
\citation{krizhevsky_learning_2009}
\citation{russakovsky_imagenet_2015}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces  Increasing the noise intensity $k$ on an ImageNet sample. Details in Table \ref  {table:noise_increase}.\relax }}{23}{figure.caption.20}\protected@file@percent }
\newlabel{fig:noise_increase}{{3.1}{23}{Increasing the noise intensity $k$ on an ImageNet sample. Details in Table \ref {table:noise_increase}.\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{23}{subfigure.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{23}{subfigure.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{23}{subfigure.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{23}{subfigure.1.4}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {}}}{23}{subfigure.1.5}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {}}}{23}{subfigure.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Experimental Settings}{23}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Datasets and Models}{23}{subsection.3.2.1}\protected@file@percent }
\newlabel{sub:datasets_models}{{3.2.1}{23}{Datasets and Models}{subsection.3.2.1}{}}
\citation{elson_asirra_2007}
\citation{simonyan_very_2015-2}
\citation{rauber_foolbox_2020}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces VGG configuration with 11 layers\relax }}{24}{table.caption.22}\protected@file@percent }
\newlabel{table:vgg11}{{3.2}{24}{VGG configuration with 11 layers\relax }{table.caption.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Attacks}{25}{subsection.3.2.2}\protected@file@percent }
\newlabel{sec:attack}{{3.2.2}{25}{Attacks}{subsection.3.2.2}{}}
\newlabel{eq:targeted}{{3.2}{25}{Attacks}{equation.3.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Assessing Robustness}{25}{section.3.3}\protected@file@percent }
\newlabel{sec:robustness}{{3.3}{25}{Assessing Robustness}{section.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Measuring Consistency: A Metric for Assessing Robustness}{25}{subsection.3.3.1}\protected@file@percent }
\newlabel{sub:consistency}{{3.3.1}{25}{Measuring Consistency: A Metric for Assessing Robustness}{subsection.3.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Consistency comparison between normal images and adversarial examples using different methods and perturbation budgets. As $\kappa $ (see \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:noisy_version}\unskip \@@italiccorr )}}) increases, the consistency decreases, more so for adversarial examples, unless we also increase the adversarial perturbation budget as seen in (b).\relax }}{26}{figure.caption.23}\protected@file@percent }
\newlabel{fig:consistency}{{3.2}{26}{Consistency comparison between normal images and adversarial examples using different methods and perturbation budgets. As $\kappa $ (see \eqref {eq:noisy_version}) increases, the consistency decreases, more so for adversarial examples, unless we also increase the adversarial perturbation budget as seen in (b).\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{26}{subfigure.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{26}{subfigure.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Shows the accuracy comparison between normal images and adversarial examples; as $\kappa $ increases, the accuracy of adversarial examples first increases before decreasing similarly to normal images.\relax }}{27}{figure.caption.24}\protected@file@percent }
\newlabel{fig:accuracies}{{3.3}{27}{Shows the accuracy comparison between normal images and adversarial examples; as $\kappa $ increases, the accuracy of adversarial examples first increases before decreasing similarly to normal images.\relax }{figure.caption.24}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Analyzing the Effect of Random Perturbations on Output Logits}{28}{subsection.3.3.2}\protected@file@percent }
\newlabel{sub:logits_differences}{{3.3.2}{28}{Analyzing the Effect of Random Perturbations on Output Logits}{subsection.3.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Comparison between the logits of an ImageNet image before ($Z(x)$) and after adding noise to the input ($Z(\tilde  {x})$). When the input is normal (A), the difference between predictions is small, but becomes larger when the input is adversarial (B).\relax }}{30}{figure.caption.25}\protected@file@percent }
\newlabel{fig:logits}{{3.4}{30}{Comparison between the logits of an ImageNet image before ($Z(x)$) and after adding noise to the input ($Z(\tilde {x})$). When the input is normal (A), the difference between predictions is small, but becomes larger when the input is adversarial (B).\relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Normal Image}}}{30}{subfigure.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Adversarial Example (BIM)}}}{30}{subfigure.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {第4章\hspace  {.3em}}Proposed Methodology}{31}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10.0pt}}
\@writefile{lot}{\addvspace {10.0pt}}
\newlabel{Methodology}{{4}{31}{Proposed Methodology}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Noise-Aided Adversarial Example Detection (NAED) Method}{31}{section.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces The framework of the discussed method.\relax }}{31}{figure.caption.26}\protected@file@percent }
\newlabel{fig:framework}{{4.1}{31}{The framework of the discussed method.\relax }{figure.caption.26}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Implementation of the NAED Method}{32}{subsection.4.1.1}\protected@file@percent }
\newlabel{sub:implementation}{{4.1.1}{32}{Implementation of the NAED Method}{subsection.4.1.1}{}}
\newlabel{alg:detection}{{0}{32}{Implementation of the NAED Method}{subsection.4.1.1}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Detection Algorithm\relax }}{32}{algorithm.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Predictions Differences: Two scores}{33}{section.4.2}\protected@file@percent }
\newlabel{sub:detection_metrics}{{4.2}{33}{Predictions Differences: Two scores}{section.4.2}{}}
\newlabel{eq:score1}{{4.1}{33}{Predictions Differences: Two scores}{equation.4.2.1}{}}
\newlabel{eq:diff}{{4.2}{33}{Predictions Differences: Two scores}{equation.4.2.2}{}}
\newlabel{eq:mean_mu}{{4.3}{33}{Predictions Differences: Two scores}{equation.4.2.3}{}}
\newlabel{eq:score2}{{4.4}{33}{Predictions Differences: Two scores}{equation.4.2.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Histograms showing the $score_{1}$ per sample type.\relax }}{34}{figure.caption.27}\protected@file@percent }
\newlabel{fig:score_1}{{4.2}{34}{Histograms showing the $score_{1}$ per sample type.\relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Normal images compared with different adversarial examples generation methods.}}}{34}{subfigure.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Normal images compared with BIM-generated samples at varying perturbation budgets.}}}{34}{subfigure.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Histograms showing the $score_{2}$ per sample type.\relax }}{35}{figure.caption.28}\protected@file@percent }
\newlabel{fig:score_2}{{4.3}{35}{Histograms showing the $score_{2}$ per sample type.\relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Normal images compared with different adversarial examples generation methods.}}}{35}{subfigure.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Normal images compared with BIM-generated samples at varying perturbation budgets.}}}{35}{subfigure.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Threshold-based Detection: A Method-Specific Approach}{36}{section.4.3}\protected@file@percent }
\newlabel{sec:method_specific_approach}{{4.3}{36}{Threshold-based Detection: A Method-Specific Approach}{section.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces ROC-AUC for each classifier and each dataset.\relax }}{36}{figure.caption.29}\protected@file@percent }
\newlabel{fig:rocs}{{4.4}{36}{ROC-AUC for each classifier and each dataset.\relax }{figure.caption.29}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {$score_1$ ImageNet}}}{36}{subfigure.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$score_2$ ImageNet}}}{36}{subfigure.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {$score_1$ D. vs. C.}}}{36}{subfigure.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {$score_2$ D. vs. C.}}}{36}{subfigure.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {$score_1$ CIFAR-10}}}{36}{subfigure.4.5}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {$score_2$ CIFAR-10}}}{36}{subfigure.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Adapting to Production: Method-Agnostic Approach}{37}{section.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Threshold and Noise Intensity Selection}{37}{subsection.4.4.1}\protected@file@percent }
\newlabel{sec:selection_of_the_intensity}{{4.4.1}{37}{Threshold and Noise Intensity Selection}{subsection.4.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Histograms showing the number of times an input was detected as positive on ImageNet.\relax }}{39}{figure.caption.30}\protected@file@percent }
\newlabel{fig:distributions_scores}{{4.5}{39}{Histograms showing the number of times an input was detected as positive on ImageNet.\relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {$score_1$}}}{39}{subfigure.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$score_2$}}}{39}{subfigure.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Scores combined}}}{39}{subfigure.5.3}\protected@file@percent }
\citation{xu_feature_2018}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Detection Results and Performance Analysis}{40}{section.4.5}\protected@file@percent }
\newlabel{sec:detection_results}{{4.5}{40}{Detection Results and Performance Analysis}{section.4.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Detection results for each dataset. Results are shown for both scores individually ($score_1$ and $score_2$) and combined ($combined$). For each attack, we specify the metric with which it was created ($\infty $ or $2$), whether the attack is targeted ($t$), and the corresponding average $L_2$ distance. \relax }}{42}{table.caption.31}\protected@file@percent }
\newlabel{tab:detection_results}{{4.1}{42}{Detection results for each dataset. Results are shown for both scores individually ($score_1$ and $score_2$) and combined ($combined$). For each attack, we specify the metric with which it was created ($\infty $ or $2$), whether the attack is targeted ($t$), and the corresponding average $L_2$ distance. \relax }{table.caption.31}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}A Real-World Example: Showcasing the Method on a Sample}{43}{subsection.4.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces  Normal image (A), adversarial perturbation (magnified by 10) (B), adversarial example (C). \relax }}{43}{figure.caption.32}\protected@file@percent }
\newlabel{fig:showcase_example_samples}{{4.6}{43}{Normal image (A), adversarial perturbation (magnified by 10) (B), adversarial example (C). \relax }{figure.caption.32}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{43}{subfigure.6.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{43}{subfigure.6.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{43}{subfigure.6.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces  comparing the number of times the thresholds are respected between a normal image and an adversarial example. $score_1$ in (A), $score_2$ in (B). \relax }}{43}{figure.caption.33}\protected@file@percent }
\newlabel{fig:showcase_scores}{{4.7}{43}{comparing the number of times the thresholds are respected between a normal image and an adversarial example. $score_1$ in (A), $score_2$ in (B). \relax }{figure.caption.33}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{43}{subfigure.7.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{43}{subfigure.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {第5章\hspace  {.3em}}Discussion and Future Work}{45}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10.0pt}}
\@writefile{lot}{\addvspace {10.0pt}}
\newlabel{discussion}{{5}{45}{Discussion and Future Work}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Addressing Low-Resolution Images}{45}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Adapting to Adaptive Adversaries}{46}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Potential Improvements and Next Steps}{47}{section.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Peak Detection Analysis}{47}{subsection.5.3.1}\protected@file@percent }
\newlabel{eq:first-order-diff}{{5.1}{47}{Peak Detection Analysis}{equation.5.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Peaks observed on normal and adversarial images. Peaks on adversarial examples appear to happen at a sooner noise intensity and reach a higher value.\relax }}{47}{figure.caption.34}\protected@file@percent }
\newlabel{fig:peaks}{{5.1}{47}{Peaks observed on normal and adversarial images. Peaks on adversarial examples appear to happen at a sooner noise intensity and reach a higher value.\relax }{figure.caption.34}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{47}{subfigure.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{47}{subfigure.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{47}{subfigure.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{47}{subfigure.1.4}\protected@file@percent }
\citation{zheng_improving_2016}
\citation{connor_survey_augmentation_2019}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Enhancing Detection Performance with Data Augmentation and Other Techniques}{48}{subsection.5.3.2}\protected@file@percent }
\citation{metzen_detecting_2017}
\citation{liang_detecting_2021}
\citation{bhagoji_dimensionality_2017}
\bibdata{references}
\@writefile{toc}{\contentsline {chapter}{总结与展望}{49}{chapter*.35}\protected@file@percent }
\newlabel{conclusion}{{5.3.2}{49}{\hnu@summaryname }{chapter*.35}{}}
\bibcite{russakovsky_imagenet_2015}{{1}{}{{}}{{}}}
\bibcite{amodei_deep_2015}{{2}{}{{}}{{}}}
\bibcite{bojarski_end_2016}{{3}{}{{}}{{}}}
\bibcite{silver_mastering_2016}{{4}{}{{}}{{}}}
\bibcite{szegedy_intriguing_2014}{{5}{}{{}}{{}}}
\bibcite{carlini_audio_2018}{{6}{}{{}}{{}}}
\bibcite{su_one_2019}{{7}{}{{}}{{}}}
\bibcite{he_deep_2015}{{8}{}{{}}{{}}}
\bibcite{vaswani_attention_2017}{{9}{}{{}}{{}}}
\bibcite{huang_densely_2018}{{10}{}{{}}{{}}}
\bibcite{srivastava_dropout_2014}{{11}{}{{}}{{}}}
\bibcite{hendrycks_benchmarking_2019}{{12}{}{{}}{{}}}
\bibcite{warren_s_mcculloch_walter_pitts_logical_1943}{{13}{}{{}}{{}}}
\bibcite{brain_perceptron_1958}{{14}{}{{}}{{}}}
\bibcite{minsky_perceptrons_1969}{{15}{}{{}}{{}}}
\bibcite{haykin_neural_1994}{{16}{}{{}}{{}}}
\@writefile{toc}{\contentsline {chapter}{参考文献}{50}{chapter*.36}\protected@file@percent }
\@writefile{lof}{\addvspace {10.0pt}}
\@writefile{lot}{\addvspace {10.0pt}}
\bibcite{rumelhart_learning_1986}{{17}{}{{}}{{}}}
\bibcite{lecun_object_1999}{{18}{}{{}}{{}}}
\bibcite{krizhevsky_imagenet_2017-1}{{19}{}{{}}{{}}}
\bibcite{zeiler_visualizing_2013}{{20}{}{{}}{{}}}
\bibcite{noauthor_model_2020}{{21}{}{{}}{{}}}
\bibcite{goodfellow_explaining_2015}{{22}{}{{}}{{}}}
\bibcite{szegedy_going_2014}{{23}{}{{}}{{}}}
\bibcite{kurakin_adversarial_2017}{{24}{}{{}}{{}}}
\bibcite{carlini_towards_2017}{{25}{}{{}}{{}}}
\bibcite{papernot_distillation_2016}{{26}{}{{}}{{}}}
\bibcite{rony_decoupling_2019}{{27}{}{{}}{{}}}
\bibcite{papernot_limitations_2015}{{28}{}{{}}{{}}}
\bibcite{carlini_adversarial_2017}{{29}{}{{}}{{}}}
\bibcite{feinman_detecting_2017}{{30}{}{{}}{{}}}
\bibcite{krizhevsky_learning_2009}{{31}{}{{}}{{}}}
\bibcite{elson_asirra_2007}{{32}{}{{}}{{}}}
\bibcite{simonyan_very_2015-2}{{33}{}{{}}{{}}}
\bibcite{rauber_foolbox_2020}{{34}{}{{}}{{}}}
\bibcite{xu_feature_2018}{{35}{}{{}}{{}}}
\bibcite{zheng_improving_2016}{{36}{}{{}}{{}}}
\bibcite{connor_survey_augmentation_2019}{{37}{}{{}}{{}}}
\bibcite{metzen_detecting_2017}{{38}{}{{}}{{}}}
\bibcite{liang_detecting_2021}{{39}{}{{}}{{}}}
\bibcite{bhagoji_dimensionality_2017}{{40}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\@writefile{toc}{\contentsline {chapter}{致\hskip 1em\relax 谢}{53}{chapter*.37}\protected@file@percent }
\@writefile{lof}{\addvspace {10.0pt}}
\@writefile{lot}{\addvspace {10.0pt}}
\ttl@finishall
\gdef \@abspage@last{70}
